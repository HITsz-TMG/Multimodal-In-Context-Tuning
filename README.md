# Multimodal-In-Context-Tuning for E-Coomerce Description Generation
Codes and Data for our LREC-COLING 2024 paper titled: [A Multimodal In-Context Tuning Approach for E-Commerce Product Description Generation](https://arxiv.org/abs/2402.13587).

If you have any question, please feel free to contact me by e-mail: liyunxin987@163.com, Twitter: [@LyxTg](https://twitter.com/LyxTg), or submit your issue in the repository.

**The main contributions are:**

1) We present a product description generation paradigm that is based only on the image and several marketing keywords. For this new setting, we propose a straightforward and effective multimodal in-context tuning approach, named ModICT, integrating the power from the frozen language model and visual encoder.

2) Our work is the first one to investigate utilizing the in-context learning and text generation capabilities of various frozen language models for multimodal E-commerce product description generation. ModICT can be plugged into various types of language models and the training process is parameter-efficient.

3) We conduct extensive experiments on our newly built three-category product datasets. The experimental results indicate that the proposed method achieves state-of-the-art performance on a wide range of evaluation metrics. Using the proposed multimodal in-context tuning technical, small models also achieve competitive performance compared to LLMs.

## Our training approach: ModICT



![](https://github.com/YunxinLi/LingCloud/blob/main/images/demo.png)




## Our Collected Data: MD2T

